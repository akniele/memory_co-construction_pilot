{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baYIbI6fZqdW"
      },
      "source": [
        "## Generate LLM descriptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTHgSA6boTc8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import PIL.Image\n",
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "api_key = userdata.get(\"GOOGLE_API_KEY\")\n",
        "genai.configure(api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlGZVQU1qYk3"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel('gemini-1.5-pro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKQ_wPQ-5Dza"
      },
      "outputs": [],
      "source": [
        "def get_all_images_by_subfolder(main_folder):\n",
        "    image_extensions = ('.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff')\n",
        "    all_images_by_subfolder = []\n",
        "\n",
        "    for root, dirs, files in os.walk(main_folder):\n",
        "        if root == main_folder:\n",
        "            continue  # Skip the main folder itself\n",
        "        subfolder_images = []\n",
        "        for file in files:\n",
        "            if file.lower().endswith(image_extensions):\n",
        "                subfolder_images.append(os.path.join(root, file))\n",
        "        if subfolder_images:\n",
        "            all_images_by_subfolder.append(subfolder_images)\n",
        "\n",
        "    return all_images_by_subfolder\n",
        "\n",
        "main_folder =  # Path to the folder containing subfolders with images\n",
        "images_by_subfolder = get_all_images_by_subfolder(main_folder)\n",
        "print(len(images_by_subfolder))\n",
        "\n",
        "prompt = \"Write a description for the given image sequence in a single paragraph, what is happening in this episode?\"\n",
        "\n",
        "found_bad = False\n",
        "\n",
        "i = 0\n",
        "\n",
        "for subfolder in images_by_subfolder:\n",
        "  print(\"unsorted\", subfolder)\n",
        "  for file_name in subfolder:\n",
        "    if \"ipynb_checkpoints\" in file_name:\n",
        "      found_bad = True\n",
        "      break\n",
        "\n",
        "  if found_bad:\n",
        "    found_bad = False\n",
        "    continue\n",
        "\n",
        "  i += 1\n",
        "\n",
        "  current_image_paths = sorted(subfolder)\n",
        "  print(current_image_paths)\n",
        "\n",
        "\n",
        "  current_images = []\n",
        "\n",
        "  for image in current_image_paths:\n",
        "      img = PIL.Image.open(image)\n",
        "      current_images.append(img)\n",
        "\n",
        "  input = [prompt] + current_images\n",
        "\n",
        "  print(prompt)\n",
        "  print(current_images)\n",
        "  print(input)\n",
        "\n",
        "  response = model.generate_content(input)\n",
        "  print(response.text)\n",
        "\n",
        "  with open(\"llm_descriptions.csv\", mode='a', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([current_image_paths[0].split('/')[-2], response.text])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSmoddrBZt4d"
      },
      "source": [
        "## Load and sort human and LLM descriptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3q-ZSCFYomh"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"human_descriptions.csv\")\n",
        "df_sorted = df.sort_values(\"image_name\", ignore_index=True)\n",
        "df_llm = pd.read_csv(\"llm_descriptions.csv\")\n",
        "df_llm_sorted = df_llm.sort_values(\"image_name\", ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4FrJTCMjkyP"
      },
      "source": [
        "## Get aggregation summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gii2Rms8josf"
      },
      "outputs": [],
      "source": [
        "text_aggregation_prompt = \"\"\"\n",
        "You will get two versions of the same story. Please provide the following information:\n",
        "\n",
        "1. Overlap: all the information that was in both versions.\n",
        "2. Complementary information: all information that is only mentioned in one of the versions, but doesn't\n",
        "conflict with anything in the other version.\n",
        "3. Conflicting information: information that conflicts between the two versions.\n",
        "\n",
        "Use exactly this format:\n",
        "\n",
        "Overlap:\n",
        "- overlap item 1\n",
        "- overlap item 2\n",
        "- ...\n",
        "\n",
        "Complementary information description 1:\n",
        "- item 1\n",
        "- item 2\n",
        "- ...\n",
        "\n",
        "Complementary information description 2:\n",
        "- item 1\n",
        "- item 2\n",
        "- ...\n",
        "\n",
        "Conflicting information:\n",
        "- item 1\n",
        "- item 2\n",
        "- ...\n",
        "\n",
        "\n",
        "Here is the first version for you to use for your answer:\n",
        "{first_description}\n",
        "\n",
        "Here is the second version for you to use for your answer:\n",
        "{second_description}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oy0tqabIkxag"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel('gemini-1.5-pro')\n",
        "\n",
        "for idx in df.index[:]:\n",
        "  desc1 = df_sorted.loc[idx, 'gt_description']\n",
        "  desc2 = df_llm_sorted.loc[idx, 'llm_description']\n",
        "\n",
        "  prompt = text_aggregation_prompt.format(first_description=desc1, second_description=desc2)\n",
        "  print(prompt)\n",
        "  response = model.generate_content(prompt)\n",
        "  with open(\"aggregation.csv\", mode='a', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([df_sorted.loc[idx, 'image_name'], response.text])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLUw8tfm2FnW"
      },
      "source": [
        "## Create files with the two descriptions and the aggregation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUl0g2Mntje9"
      },
      "source": [
        "#### full data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UonRnWje2MfZ"
      },
      "outputs": [],
      "source": [
        "df_desc1 = pd.read_csv(\"human_descriptions.csv\")\n",
        "df_desc1 = df_desc1.sort_values(\"image_name\", ignore_index=True)\n",
        "df_desc2 = pd.read_csv(\"llm_descriptions.csv\")\n",
        "df_desc2 = df_desc2.sort_values(\"image_name\", ignore_index=True)\n",
        "df_aggr = pd.read_csv(\"aggregation.csv\")\n",
        "df_aggr = df_aggr.sort_values(\"image_name\", ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeOmc5BNq3pK"
      },
      "source": [
        "#### partial data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yzlv8U2dqWL-"
      },
      "outputs": [],
      "source": [
        "df_desc1_partial = pd.read_csv(\"description_partial.csv\")\n",
        "df_desc1_partial = df_desc1_partial.sort_values(\"image_name\", ignore_index=True)\n",
        "df_desc2_partial = pd.read_csv(\"llm_description_partial.csv\")\n",
        "df_desc2_partial = df_desc2_partial.sort_values(\"image_name\", ignore_index=True)\n",
        "df_aggr_partial = pd.read_csv(\"aggregation_partial.csv\")\n",
        "df_aggr_partial = df_aggr_partial.sort_values(\"image_name\", ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZVteeWrJgBz"
      },
      "source": [
        "#### combining full and partial data per participant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KX0dF1p3s-1m"
      },
      "outputs": [],
      "source": [
        "participants = [{\"full\": [\"cmc_2.png\", \"cmc_40.png\", \"cmc_68.png\"], \"partial\": [\"cmc_34.png\", \"cmc_60.png\"]},\n",
        "               {\"full\": [\"cmc_34.png\", \"cmc_60.png\"], \"partial\": [\"cmc_2.png\", \"cmc_40.png\", \"cmc_68.png\"]},\n",
        "               {\"full\": [\"cmc_68.png\", \"cmc_40.png\", \"cmc_2.png\"], \"partial\": [\"cmc_60.png\", \"cmc_34.png\"]},\n",
        "               {\"full\": [\"cmc_60.png\", \"cmc_34.png\"], \"partial\": [\"cmc_68.png\", \"cmc_40.png\", \"cmc_2.png\"]}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GepiAv3Qs-zd"
      },
      "outputs": [],
      "source": [
        "merged_full = pd.merge(df_desc1, df_desc2, how=\"outer\", on=[\"image_name\"])\n",
        "merged_full = pd.merge(merged_full, df_aggr, how=\"outer\", on=[\"image_name\"])\n",
        "merged_partial = pd.merge(df_desc1_partial, df_desc2_partial, how=\"outer\", on=[\"image_name\"])\n",
        "merged_partial = pd.merge(merged_partial, df_aggr_partial, how=\"outer\", on=[\"image_name\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bzi8yzYs-xX"
      },
      "outputs": [],
      "source": [
        "for i in range(4): # iterating over participants list\n",
        "  full_samples = participants[i][\"full\"]\n",
        "  partial_samples = participants[i][\"partial\"]\n",
        "\n",
        "  df_full_temp = merged_full[merged_full[\"image_name\"].isin(full_samples)]\n",
        "  df_partial_temp = merged_partial[merged_partial[\"image_name\"].isin(partial_samples)]\n",
        "\n",
        "  df_participant = pd.concat([df_full_temp, df_partial_temp])\n",
        "  df_participant = df_participant.drop(\"image_name\", axis=1)\n",
        "\n",
        "  df_participant['ID'] = df_participant.index\n",
        "\n",
        "  df_participant = df_participant.rename(columns={\"gt_description\": \"Text1\", \"llm_description\": \"Text2\", \"aggregation\": \"Summary\"})\n",
        "\n",
        "  cols = df_participant.columns.tolist()\n",
        "  cols = cols[-1:] + cols[:-1]\n",
        "  df_participant = df_participant[cols]\n",
        "\n",
        "  df_participant = df_participant.sort_values(\"ID\")\n",
        "\n",
        "  df_participant.to_csv(f\"participant_{i+1}_data.tsv\", sep=\"\\t\", index=False) # save to file"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "baYIbI6fZqdW",
        "CSmoddrBZt4d",
        "W4FrJTCMjkyP",
        "KUl0g2Mntje9",
        "qeOmc5BNq3pK",
        "bZVteeWrJgBz"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
